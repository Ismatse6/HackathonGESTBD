{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4d4719",
   "metadata": {},
   "source": [
    "# PDFPLUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def scrapPDF(ruta):\n",
    "    tablas = []\n",
    "\n",
    "    with pdfplumber.open(ruta) as pdf:\n",
    "        for pagina in pdf.pages:\n",
    "            for tabla in pagina.extract_tables():\n",
    "                if tabla and len(tabla) > 1:\n",
    "                    tablas.append(tabla)\n",
    "\n",
    "    encabezados_objetivo = {\"nombre\", \"tipo\", \"observaciones\"}\n",
    "    indice_inicio = None\n",
    "\n",
    "    for i, tabla in enumerate(tablas):\n",
    "        encabezados = [str(celda).strip().lower() for celda in tabla[0] if celda]\n",
    "        if encabezados_objetivo.issubset(set(encabezados)):\n",
    "            indice_inicio = i\n",
    "            break\n",
    "\n",
    "    if indice_inicio is not None:\n",
    "        tablas_relevantes = tablas[indice_inicio:]\n",
    "        dfs = []\n",
    "\n",
    "        for tabla in tablas_relevantes:\n",
    "            # Generar encabezados seguros y únicos\n",
    "            colnames = []\n",
    "            counts = {}\n",
    "            for i, c in enumerate(tabla[0]):\n",
    "                name = str(c).strip() if c else f\"col_{i}\"\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "                if counts[name] > 1:\n",
    "                    name = f\"{name}_{counts[name]}\"\n",
    "                colnames.append(name)\n",
    "\n",
    "            df_temp = pd.DataFrame(tabla[1:], columns=colnames)\n",
    "\n",
    "            # Limpiar columnas duplicadas o vacías\n",
    "            df_temp = df_temp.loc[:, ~df_temp.columns.duplicated()]\n",
    "            df_temp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            dfs.append(df_temp)\n",
    "\n",
    "        # Concatenar todas las tablas (aunque tengan columnas distintas)\n",
    "        df = pd.concat(dfs, ignore_index=True, join='outer')\n",
    "        df = df.loc[:, ~df.columns.duplicated()]  # eliminar duplicadas finales\n",
    "\n",
    "        # Limpieza opcional\n",
    "        if \"Nombre\" in df.columns:\n",
    "            df = df[df[\"Tipo\"] == \"Bibliografía\"]\n",
    "            df[\"Nombre\"] = df[\"Nombre\"].astype(str).str.replace(\"\\\\n\", \" \", regex=False)\n",
    "            df = df[~df[\"Nombre\"].str.contains(r\"^https?://\", na=False)]\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Guias Docentes\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".pdf\"):  \n",
    "        ruta = os.path.join(directory, file)\n",
    "        df = scrapPDF(ruta)  \n",
    "\n",
    "        if not df.empty:  \n",
    "            df[\"archivo_origen\"] = file  \n",
    "            dfs.append(df)\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8891e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrapGoogleScholar(name):\n",
    "    url = f\"https://scholar.google.com/scholar?q={quote(name)}\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    respuesta = requests.get(url, headers=headers)\n",
    "    if respuesta.status_code != 200:\n",
    "        raise Exception(f\"Error al acceder a Google Scholar: {respuesta.status_code}\")\n",
    "\n",
    "    html = respuesta.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    resultado = {}\n",
    "    item = soup.select_one(\".gs_r.gs_or.gs_scl\")\n",
    "\n",
    "    if item:\n",
    "        titulo_elem = item.select_one(\".gs_rt\")\n",
    "        autor_elem = item.select_one(\".gs_a\")\n",
    "        link_elem = titulo_elem.find(\"a\") if titulo_elem else None\n",
    "\n",
    "        titulo = titulo_elem.get_text(strip=True) if titulo_elem else \"\"\n",
    "        autores = autor_elem.get_text(strip=True) if autor_elem else \"\"\n",
    "        enlace = link_elem[\"href\"] if link_elem and link_elem.has_attr(\"href\") else \"\"\n",
    "\n",
    "        resultado[\"Título\"] = titulo.replace(\"[PDF]\", \"\").strip()\n",
    "        resultado[\"Autores\"] = autores.split(\"-\")[0].strip()\n",
    "        resultado[\"Enlace\"] = enlace\n",
    "\n",
    "    return resultado\n",
    "\n",
    "dfs_resultado = []\n",
    "\n",
    "for index, fila in df.iterrows():\n",
    "    nombre = fila[\"Nombre\"]\n",
    "\n",
    "    dict_bibliografia = scrapGoogleScholar(nombre)\n",
    "    df_temp = pd.DataFrame([dict_bibliografia])  \n",
    "    dfs_resultado.append(df_temp)\n",
    "\n",
    "df_final = pd.concat(dfs_resultado, ignore_index=True)\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ad2fb",
   "metadata": {},
   "source": [
    "# Conectar a PostGreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9c85a",
   "metadata": {},
   "source": [
    "CREATE TABLE asignaturas (\n",
    "    id INT PRIMARY KEY\n",
    ");\n",
    "\n",
    "CREATE TABLE bibliografias (\n",
    "    id INT PRIMARY KEY,\n",
    "    asignaturaId INT,  -- primero se declara la columna\n",
    "    nombre VARCHAR(100),\n",
    "    autores VARCHAR(100),\n",
    "    url VARCHAR(200),\n",
    "    FOREIGN KEY (asignaturaId) REFERENCES asignaturas(id)  -- luego se define la FK\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e80b790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "usuario = \"userPSQL\"\n",
    "contraseña = \"passPSQL\"\n",
    "host = \"localhost\"  \n",
    "puerto = \"5432\"\n",
    "base_datos = \"postgres\"\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{usuario}:{contraseña}@{host}:{puerto}/{base_datos}\"\n",
    ")\n",
    "\n",
    "df_final.to_sql('bibliografias', engine, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37c487",
   "metadata": {},
   "source": [
    "# Competencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1711fb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
